# The script shows how to compute the histograms of the number of subjects vs total frequency for subjects having same count  for a given RDF file

register s3n://uw-cse-344-oregon.aws.amazon.com/myudfs.jar

#raw = LOAD 's3n://uw-cse-344-oregon.aws.amazon.com/cse344-test-file' USING TextLoader as (line:chararray);

raw = LOAD 's3n://uw-cse-344-oregon.aws.amazon.com/btc-2010-chunk-000' USING TextLoader as (line:chararray); 

ntriples = foreach raw generate FLATTEN(myudfs.RDFSplit3(line)) as (subject:chararray,predicate:chararray,object:chararray);

# We execute 50 reduce jobs according to the nodes we have taken on AWS
subjects = group ntriples by (subject) PARALLEL 50;

count_by_subject = foreach subjects generate flatten($0), COUNT($1) as inter_count PARALLEL 50;

inter_counts = group count_by_subject by (inter_count) PARALLEL 50;

count_by_subject_count = foreach inter_counts generate flatten($0) as subject_count, COUNT($1) as total_count PARALLEL 50;

#For debugging
# store count_by_subject_count into '/tmp/finalOutput' using PigStorage();

#Store on AWS
store count_by_subject_count into '/user/hadoop/histogram' using PigStorage();

